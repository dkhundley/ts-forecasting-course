{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: if you feel like your Pandas skills need a bit of a touch up, check [this article out](https://levelup.gitconnected.com/20-pandas-functions-for-80-of-your-data-science-tasks-b610c8bfe63c)!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we're going to be using is one of the most realistic retail time-series datasets you'll find out there because, well, it's actual Walmart data. It was made available for a Kaggle competition that you can check out [here](https://www.kaggle.com/c/m5-forecasting-accuracy).\n",
    "\n",
    "The original format of the data was in a \"wide\" format to made it smaller in memory, but that doesn't really work too well with databases and you won't see that very often in the real world. The most notable changes are that I added in a date column to replace the date identifier columns that were previously there, and I made the data smaller by only subsetting to the state of Texas.\n",
    "\n",
    "**Another note:** If you want to develop and test your code with a smaller dataset (which I'd probably recommend), set `sampled` in the cell below to `True`. All of the tests will still pass if your code is correct!\n",
    "\n",
    "Let's get into it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "sampled = True\n",
    "\n",
    "path_suffix = '' if not sampled else '_sampled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data in the right format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-series data has to be collected from some real-world, data-generating process. That means that raw data comes in as a series of observations. Depending on your experience with time-series data, you may be used to data that looks like this:\n",
    "\n",
    "| Date       | Sales |\n",
    "|------------|-------|\n",
    "| 2022-01-01 |  23   |\n",
    "| 2022-01-02 |  45   |\n",
    "| 2022-01-03 |  12   |\n",
    "| 2022-01-04 |  67   |\n",
    "| 2022-01-05 |  89   |\n",
    "\n",
    "But, if you're in retail, each of those \"sales\" probably came in some JSON from some point-of-sale system (i.e. cash register) that probably looked something like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"timestamp\": 2022-01-01 12:34:56,\n",
    "    \"product_id\": 5,\n",
    "    \"store_id\": 12,\n",
    "    \"category_id\": 36,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Usually, it's the job of a data engineer to collect all of these records and aggregate them into a nice, tabular format, but it's worth at least having an appreciation for how it's done. So, we're going to start from a mock version of a transactions table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01 13:41:03</td>\n",
       "      <td>HOBBIES_1_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01 07:30:52</td>\n",
       "      <td>HOBBIES_1_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01 11:17:38</td>\n",
       "      <td>HOBBIES_1_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01 06:07:58</td>\n",
       "      <td>HOBBIES_1_004_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01 21:51:07</td>\n",
       "      <td>HOBBIES_1_004_TX_2_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_2</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                             id        item_id   \n",
       "0  2013-01-01 13:41:03  HOBBIES_1_004_TX_1_evaluation  HOBBIES_1_004  \\\n",
       "1  2013-01-01 07:30:52  HOBBIES_1_004_TX_1_evaluation  HOBBIES_1_004   \n",
       "2  2013-01-01 11:17:38  HOBBIES_1_004_TX_1_evaluation  HOBBIES_1_004   \n",
       "3  2013-01-01 06:07:58  HOBBIES_1_004_TX_2_evaluation  HOBBIES_1_004   \n",
       "4  2013-01-01 21:51:07  HOBBIES_1_004_TX_2_evaluation  HOBBIES_1_004   \n",
       "\n",
       "     dept_id   cat_id store_id state_id  \n",
       "0  HOBBIES_1  HOBBIES     TX_1       TX  \n",
       "1  HOBBIES_1  HOBBIES     TX_1       TX  \n",
       "2  HOBBIES_1  HOBBIES     TX_1       TX  \n",
       "3  HOBBIES_1  HOBBIES     TX_2       TX  \n",
       "4  HOBBIES_1  HOBBIES     TX_2       TX  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv(f'{data_dir}/transactions_data{path_suffix}.csv')\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        object\n",
       "id          object\n",
       "item_id     object\n",
       "dept_id     object\n",
       "cat_id      object\n",
       "store_id    object\n",
       "state_id    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this is a DataFrame where each row relates to purchases for an individual item. Here's a little data dictionary:\n",
    "\n",
    "- `date`: the time at which an item was bought, down to the second\n",
    "- `id`: the product ID. Each of these is an individual item at a specific store.\n",
    "- `item_id`: this is an identifier for items, but not at the store level. You can use this to find the same item at different stores.\n",
    "- `dept_id`: department ID. One level up from `item_id` in the hierarchy\n",
    "- `cat_id`: category ID. One level up from `dept_id` in the hierarchy\n",
    "- `store_id`: identifies the specific store where the product was bought\n",
    "- `state_id`: identifies the specific state where the product was bought\n",
    "\n",
    "`date` is supposed to be a `datetime`-like object, but you can see that when we loaded it from disk, it was loaded in as a string. Let's convert that column to `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Convert this column to a datetime object\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to transform this dataset into one that's easy to analyze and train models on. For this project, our goal is going to be to work at the daily level. So, our first step is to aggregate our transactions data up to the daily level.\n",
    "\n",
    "To be more specific, this is what we want it to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>HOBBIES_1_004_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>HOBBIES_2_075_TX_1_evaluation</td>\n",
       "      <td>HOBBIES_2_075</td>\n",
       "      <td>HOBBIES_2</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>HOUSEHOLD_1_247_TX_1_evaluation</td>\n",
       "      <td>HOUSEHOLD_1_247</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>HOUSEHOLD_1_266_TX_1_evaluation</td>\n",
       "      <td>HOUSEHOLD_1_266</td>\n",
       "      <td>HOUSEHOLD_1</td>\n",
       "      <td>HOUSEHOLD</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>FOODS_1_001_TX_1_evaluation</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>TX_1</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                               id          item_id      dept_id   \n",
       "0  2013-01-01    HOBBIES_1_004_TX_1_evaluation    HOBBIES_1_004    HOBBIES_1  \\\n",
       "1  2013-01-01    HOBBIES_2_075_TX_1_evaluation    HOBBIES_2_075    HOBBIES_2   \n",
       "2  2013-01-01  HOUSEHOLD_1_247_TX_1_evaluation  HOUSEHOLD_1_247  HOUSEHOLD_1   \n",
       "3  2013-01-01  HOUSEHOLD_1_266_TX_1_evaluation  HOUSEHOLD_1_266  HOUSEHOLD_1   \n",
       "4  2013-01-01      FOODS_1_001_TX_1_evaluation      FOODS_1_001      FOODS_1   \n",
       "\n",
       "      cat_id store_id state_id  sales  \n",
       "0    HOBBIES     TX_1       TX      3  \n",
       "1    HOBBIES     TX_1       TX      0  \n",
       "2  HOUSEHOLD     TX_1       TX      0  \n",
       "3  HOUSEHOLD     TX_1       TX      0  \n",
       "4      FOODS     TX_1       TX      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a hefty table, so just peeking at the first 5 rows\n",
    "pd.read_csv(f'{data_dir}/sales_data{path_suffix}.csv', nrows=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the `sales` column is really just a daily count of transactions for that particular `id`.\n",
    "\n",
    "In the cell below, create a dataframe called `data`, which is the transactions dataframe aggregated to the daily level. It should look like the above, except you won't have zero sales days. Don't worry about order: the below test will handle that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transactions.groupby(by = [pd.Grouper(key = 'date', freq = 'D'), 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']).size().reset_index().rename(columns = {0: 'sales'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cell below runs without error, you did it right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sales_eq(data):\n",
    "    assert (\n",
    "        pd.read_csv(f'{data_dir}/sales_data{path_suffix}.csv', usecols=['date', 'id', 'sales'])\n",
    "        .assign(date=lambda df: pd.to_datetime(df.date))\n",
    "        .query('sales != 0')\n",
    "        .merge(data, on=['date', 'id'], how='left', suffixes=('_actual', '_predicted'))\n",
    "        .fillna(0)\n",
    "        .assign(sales_error=lambda df: (df.sales_actual - df.sales_predicted).abs())\n",
    "        .sales_error\n",
    "        .sum() < 1e-6\n",
    "    ), 'Your version of sales does not match the original sales data.'\n",
    "\n",
    "    assert (\n",
    "        pd.read_csv(f'{data_dir}/sales_data{path_suffix}.csv', usecols=['date', 'id', 'sales'])\n",
    "        .query('sales != 0')\n",
    "        .shape[0]\n",
    "    ) == data.shape[0], 'Your dataframe has a different number of rows than the original sales data.'\n",
    "\n",
    "test_sales_eq(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how our data is being stored in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13345 entries, 0 to 13344\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      13345 non-null  datetime64[ns]\n",
      " 1   id        13345 non-null  object        \n",
      " 2   item_id   13345 non-null  object        \n",
      " 3   dept_id   13345 non-null  object        \n",
      " 4   cat_id    13345 non-null  object        \n",
      " 5   store_id  13345 non-null  object        \n",
      " 6   state_id  13345 non-null  object        \n",
      " 7   sales     13345 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(6)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 GB of data for our purposed is certainly no joke. But how much of that is really necessary?\n",
    "\n",
    "Most of our data is stored in the least memory efficient format for pandas: strings (objects). Let's fix that.\n",
    "\n",
    "Hint: check out [this page](https://pandas.pydata.org/docs/user_guide/basics.html#basics-dtypes) of the pandas documentation that talks about data types.\n",
    "\n",
    "In the below cell, convert the data types of columns to reduce memory usage as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my solution, I got the final DataFrame down to 90.4 MB, which is about 6% of the original size!\n",
    "\n",
    "While we're at it, it's worth talking about the best way to store this data on disk. If we saved this as a CSV, it wouldn't maintain any of the data type modifications we just made. Pandas offers a bunch of options for saving DataFrames, but here are the two I'd recommend:\n",
    "\n",
    "- [Parquet](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.to_parquet.html) has basically become the industry standard for storing tabular data on disk. It's a columnar file format that automatically compresses your data (which it does really well) and will maintain any data types you use in Pandas, with only a couple exceptions.\n",
    "\n",
    "- [Feather](https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.to_parquet.html) is also a columnar data format, but it optimizes heavily for read speed. Your file size will be much bigger than Parquets, but it's really useful when you need to heavily optimize for data reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet('sales_data_checkpoint.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('sales_data_checkpoint.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my local machine, loading our original CSV took ~8.7 seconds, and that only took 0.1 seconds. And our data types were maintained! Nice!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finishing up our data pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one last modification we need to make to our data before it's ready to go. The way that we converted transactions into sales was *slightly* problematic because now, when a product doesn't sell it just isn't present in our data, rather than appearing as a zero. \n",
    "\n",
    "That's an issue for our forecasting models, so let's fix it!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set your index to columns that the DataFrame is distinct on (`date` and `id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a MultiIndex with all combinations of daily dates and `id`s using `pd.MultiIndex.from_product` and use it and `.reindex()` to fill the gaps in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "index_to_select = ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, fill the resulting `NaN`s in your dataframe. Hint: it's tempting to use `.groupby().fillna(method='ffill')` (and backfilling), but unfortunately this method is quite slow on grouped data. I'd recommend manually recreating the categorical columns by splitting the `id` column on underscores. This cell could take over a minute to run depending on how you implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sales_eq(data):\n",
    "    data_copy = (\n",
    "        data\n",
    "        .copy()\n",
    "        .reset_index('id')\n",
    "        .assign(id=lambda df: df.id.astype(str).values)\n",
    "    )\n",
    "    assert (\n",
    "        pd.read_csv(f'{data_dir}/sales_data{path_suffix}.csv', usecols=['date', 'id', 'sales'])\n",
    "        .query('id != \"FOODS_2_394_TX_3_evaluation\"')  # this item is missing in my modified data\n",
    "        .assign(date=lambda df: pd.to_datetime(df.date))\n",
    "        .merge(\n",
    "            data_copy, \n",
    "            on=['date', 'id'], \n",
    "            how='left', \n",
    "            suffixes=('_actual', '_predicted')\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .assign(sales_error=lambda df: (df.sales_actual - df.sales_predicted).abs())\n",
    "        .sales_error\n",
    "        .sum() < 1e-6\n",
    "    ), 'Your version of sales does not match the original sales data.'\n",
    "\n",
    "test_sales_eq(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis is crucial for building the best models.\n",
    "\n",
    "Before you start this section, though, I would **highly recommend** that you set the index of your DataFrame to be on both the `date` and `id` field (our DataFrame has one row for each `date`/`id` combo). It's up to you, but it's good practice!\n",
    "\n",
    "For this section, find 3-5 insights about the data that you feel are helpful for building models. Specifically, we'll be building models at the `date`/`dept_id` level (i.e., a forecast for `FOODS_1` on 2011-02-01, 2011-02-02, etc., a forecast for `HOBBIES_1` on 2011-02-01, 2011-02-02, etc.)\n",
    "\n",
    "The only required one is an [autocorrelation analysis](https://pandas.pydata.org/docs/reference/api/pandas.plotting.autocorrelation_plot.html). Other than that, some ideas are:\n",
    "\n",
    "- Looking for seasonal patterns and trends for each department\n",
    "- Department sales by day of week\n",
    "- Analyses at a higher level, like the category level\n",
    "\n",
    "Anything goes! Be creative!\n",
    "\n",
    "Here's an example of plotting the category-level sales for `FOODS_1` to get you started:\n",
    "\n",
    "```\n",
    "(\n",
    "    data\n",
    "    .groupby(['date', 'dept_id'])\n",
    "    .sales\n",
    "    .sum()\n",
    "    [:, 'FOODS_1']\n",
    "    .plot()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training some models!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train some models!\n",
    "\n",
    "We're going to use the [statsforecast](https://github.com/Nixtla/statsforecast) library, since it makes training statistical time-series models really easy. There are other great libraries (like [darts](https://unit8co.github.io/darts/), which is more mature of a package) but I like `statsforecast` a bit more for these models. Eventually, we'll get to training our own models from scratch.\n",
    "\n",
    "Here's what you need to do:\n",
    "\n",
    "1. Aggregate sales up to the `date`/`dept_id` level so each date has 7 distinct records (one for each `dept_id`).\n",
    "2. Convert your aggregated data into the [format that `statsforecast` likes](https://nixtla.github.io/statsforecast/examples/getting_started_short.html).\n",
    "3. Fit and evaluate some models! This part is made straightforward by `statsforecast` so feel free to fit whatever you want, but focus on models like [this one](https://nixtla.github.io/statsforecast/models.html#arima-family) and [this one](https://nixtla.github.io/statsforecast/models.html#holt-winters-method) since we discussed them. Their documentation has a [quickstart](https://nixtla.github.io/statsforecast/examples/getting_started_short.html) to get going. I provided you with some helper code below to get started.\n",
    "    - Play around with `ARIMA` and `HoltWinters` and tune them using your intution, then compare them to [`AutoARIMA`](https://nixtla.github.io/statsforecast/models.html#autoarima) and [`AutoETS`](https://nixtla.github.io/statsforecast/models.html#autoets), which do the tuning for you!\n",
    "4. (If your time permits) try out other libraries! Go try to fit a [Prophet](https://facebook.github.io/prophet/docs/quick_start.html#python-api) model, fit some models using `darts` and see how they compare, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsforecast==1.5.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\david\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas64__v0.3.21-gcc_10_3_0.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached statsforecast-1.5.0-py3-none-any.whl (99 kB)\n",
      "Collecting matplotlib (from statsforecast==1.5.0)\n",
      "  Downloading matplotlib-3.7.1-cp310-cp310-win_amd64.whl (7.6 MB)\n",
      "                                              0.0/7.6 MB ? eta -:--:--\n",
      "                                              0.0/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "                                              0.1/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -                                        0.2/7.6 MB 1.5 MB/s eta 0:00:06\n",
      "     -                                        0.2/7.6 MB 1.3 MB/s eta 0:00:06\n",
      "     -                                        0.3/7.6 MB 1.4 MB/s eta 0:00:06\n",
      "     --                                       0.4/7.6 MB 1.4 MB/s eta 0:00:06\n",
      "     --                                       0.5/7.6 MB 1.5 MB/s eta 0:00:05\n",
      "     --                                       0.6/7.6 MB 1.5 MB/s eta 0:00:05\n",
      "     ---                                      0.7/7.6 MB 1.6 MB/s eta 0:00:05\n",
      "     ---                                      0.7/7.6 MB 1.6 MB/s eta 0:00:05\n",
      "     ----                                     0.8/7.6 MB 1.7 MB/s eta 0:00:05\n",
      "     ----                                     1.0/7.6 MB 1.7 MB/s eta 0:00:04\n",
      "     -----                                    1.1/7.6 MB 1.8 MB/s eta 0:00:04\n",
      "     ------                                   1.2/7.6 MB 1.8 MB/s eta 0:00:04\n",
      "     ------                                   1.3/7.6 MB 1.8 MB/s eta 0:00:04\n",
      "     -------                                  1.4/7.6 MB 1.9 MB/s eta 0:00:04\n",
      "     -------                                  1.5/7.6 MB 1.9 MB/s eta 0:00:04\n",
      "     --------                                 1.6/7.6 MB 2.0 MB/s eta 0:00:03\n",
      "     ---------                                1.8/7.6 MB 2.0 MB/s eta 0:00:03\n",
      "     ----------                               2.0/7.6 MB 2.1 MB/s eta 0:00:03\n",
      "     -----------                              2.1/7.6 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------                             2.3/7.6 MB 2.2 MB/s eta 0:00:03\n",
      "     ------------                             2.5/7.6 MB 2.3 MB/s eta 0:00:03\n",
      "     -------------                            2.6/7.6 MB 2.4 MB/s eta 0:00:03\n",
      "     --------------                           2.8/7.6 MB 2.4 MB/s eta 0:00:02\n",
      "     ---------------                          3.0/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "     ----------------                         3.2/7.6 MB 2.5 MB/s eta 0:00:02\n",
      "     -----------------                        3.3/7.6 MB 2.6 MB/s eta 0:00:02\n",
      "     ------------------                       3.5/7.6 MB 2.6 MB/s eta 0:00:02\n",
      "     -------------------                      3.7/7.6 MB 2.7 MB/s eta 0:00:02\n",
      "     --------------------                     3.8/7.6 MB 2.7 MB/s eta 0:00:02\n",
      "     ---------------------                    4.0/7.6 MB 2.7 MB/s eta 0:00:02\n",
      "     ----------------------                   4.2/7.6 MB 2.8 MB/s eta 0:00:02\n",
      "     -----------------------                  4.4/7.6 MB 2.8 MB/s eta 0:00:02\n",
      "     ------------------------                 4.6/7.6 MB 2.9 MB/s eta 0:00:02\n",
      "     -------------------------                4.8/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "     --------------------------               5.0/7.6 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------              5.2/7.6 MB 3.0 MB/s eta 0:00:01\n",
      "     ----------------------------             5.4/7.6 MB 3.0 MB/s eta 0:00:01\n",
      "     -----------------------------            5.7/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------           5.9/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------           5.9/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------          6.1/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     --------------------------------         6.3/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------        6.4/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ----------------------------------       6.6/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     -----------------------------------      6.8/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------------     6.9/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------    7.1/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     --------------------------------------   7.3/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.5/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 3.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.6/7.6 MB 3.1 MB/s eta 0:00:00\n",
      "Collecting numba>=0.55.0 (from statsforecast==1.5.0)\n",
      "  Downloading numba-0.56.4-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "                                              0.0/2.5 MB ? eta -:--:--\n",
      "     ---                                      0.2/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "     ------                                   0.4/2.5 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------                                0.6/2.5 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------                             0.8/2.5 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------                          1.0/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "     -------------------                      1.2/2.5 MB 4.2 MB/s eta 0:00:01\n",
      "     -----------------------                  1.4/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "     --------------------------               1.6/2.5 MB 4.3 MB/s eta 0:00:01\n",
      "     ------------------------------           1.9/2.5 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------        2.0/2.5 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    2.3/2.5 MB 4.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 4.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsforecast==1.5.0) (1.24.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsforecast==1.5.0) (2.0.0)\n",
      "Collecting plotly (from statsforecast==1.5.0)\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "                                              0.0/15.3 MB ? eta -:--:--\n",
      "                                              0.3/15.3 MB 5.8 MB/s eta 0:00:03\n",
      "     -                                        0.5/15.3 MB 5.6 MB/s eta 0:00:03\n",
      "     --                                       0.8/15.3 MB 5.6 MB/s eta 0:00:03\n",
      "     --                                       1.0/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     ---                                      1.2/15.3 MB 5.6 MB/s eta 0:00:03\n",
      "     ----                                     1.5/15.3 MB 5.5 MB/s eta 0:00:03\n",
      "     ----                                     1.8/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     -----                                    2.0/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     ------                                   2.3/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     ------                                   2.6/15.3 MB 5.4 MB/s eta 0:00:03\n",
      "     -------                                  2.9/15.3 MB 5.5 MB/s eta 0:00:03\n",
      "     --------                                 3.1/15.3 MB 5.5 MB/s eta 0:00:03\n",
      "     --------                                 3.4/15.3 MB 5.5 MB/s eta 0:00:03\n",
      "     ---------                                3.8/15.3 MB 5.6 MB/s eta 0:00:03\n",
      "     ----------                               4.0/15.3 MB 5.6 MB/s eta 0:00:03\n",
      "     -----------                              4.2/15.3 MB 5.5 MB/s eta 0:00:03\n",
      "     -----------                              4.3/15.3 MB 5.3 MB/s eta 0:00:03\n",
      "     -----------                              4.5/15.3 MB 5.2 MB/s eta 0:00:03\n",
      "     ------------                             4.8/15.3 MB 5.3 MB/s eta 0:00:03\n",
      "     -------------                            5.1/15.3 MB 5.3 MB/s eta 0:00:02\n",
      "     --------------                           5.4/15.3 MB 5.4 MB/s eta 0:00:02\n",
      "     ---------------                          5.8/15.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ---------------                          6.0/15.3 MB 5.5 MB/s eta 0:00:02\n",
      "     ----------------                         6.3/15.3 MB 5.5 MB/s eta 0:00:02\n",
      "     -----------------                        6.6/15.3 MB 5.6 MB/s eta 0:00:02\n",
      "     ------------------                       7.0/15.3 MB 5.7 MB/s eta 0:00:02\n",
      "     -------------------                      7.3/15.3 MB 5.7 MB/s eta 0:00:02\n",
      "     -------------------                      7.6/15.3 MB 5.8 MB/s eta 0:00:02\n",
      "     --------------------                     8.0/15.3 MB 5.8 MB/s eta 0:00:02\n",
      "     ---------------------                    8.3/15.3 MB 5.9 MB/s eta 0:00:02\n",
      "     ----------------------                   8.7/15.3 MB 5.8 MB/s eta 0:00:02\n",
      "     -----------------------                  9.1/15.3 MB 5.9 MB/s eta 0:00:02\n",
      "     ------------------------                 9.4/15.3 MB 6.0 MB/s eta 0:00:01\n",
      "     -------------------------                9.8/15.3 MB 6.0 MB/s eta 0:00:01\n",
      "     --------------------------               10.1/15.3 MB 6.1 MB/s eta 0:00:01\n",
      "     ---------------------------              10.5/15.3 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------             10.9/15.3 MB 6.2 MB/s eta 0:00:01\n",
      "     -----------------------------            11.2/15.3 MB 6.2 MB/s eta 0:00:01\n",
      "     ------------------------------           11.6/15.3 MB 6.4 MB/s eta 0:00:01\n",
      "     -------------------------------          12.0/15.3 MB 6.5 MB/s eta 0:00:01\n",
      "     --------------------------------         12.3/15.3 MB 6.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        12.7/15.3 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       13.1/15.3 MB 6.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      13.5/15.3 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------------------     13.9/15.3 MB 6.8 MB/s eta 0:00:01\n",
      "     -------------------------------------    14.3/15.3 MB 7.0 MB/s eta 0:00:01\n",
      "     --------------------------------------   14.7/15.3 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.1/15.3 MB 7.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.3/15.3 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.3/15.3 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.3/15.3 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.7.3 (from statsforecast==1.5.0)\n",
      "  Downloading scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "                                              0.0/42.5 MB ? eta -:--:--\n",
      "                                              0.3/42.5 MB 10.6 MB/s eta 0:00:04\n",
      "                                              0.8/42.5 MB 10.5 MB/s eta 0:00:04\n",
      "     -                                        1.2/42.5 MB 9.9 MB/s eta 0:00:05\n",
      "     -                                        1.7/42.5 MB 9.2 MB/s eta 0:00:05\n",
      "     -                                        2.1/42.5 MB 8.8 MB/s eta 0:00:05\n",
      "     --                                       2.4/42.5 MB 9.2 MB/s eta 0:00:05\n",
      "     --                                       2.8/42.5 MB 9.0 MB/s eta 0:00:05\n",
      "     ---                                      3.3/42.5 MB 9.1 MB/s eta 0:00:05\n",
      "     ---                                      3.7/42.5 MB 9.2 MB/s eta 0:00:05\n",
      "     ---                                      4.2/42.5 MB 8.9 MB/s eta 0:00:05\n",
      "     ----                                     4.7/42.5 MB 9.0 MB/s eta 0:00:05\n",
      "     ----                                     5.1/42.5 MB 9.1 MB/s eta 0:00:05\n",
      "     -----                                    5.6/42.5 MB 9.1 MB/s eta 0:00:05\n",
      "     -----                                    6.0/42.5 MB 9.1 MB/s eta 0:00:04\n",
      "     ------                                   6.5/42.5 MB 9.3 MB/s eta 0:00:04\n",
      "     ------                                   7.0/42.5 MB 9.3 MB/s eta 0:00:04\n",
      "     -------                                  7.5/42.5 MB 9.4 MB/s eta 0:00:04\n",
      "     -------                                  8.0/42.5 MB 9.3 MB/s eta 0:00:04\n",
      "     -------                                  8.4/42.5 MB 9.3 MB/s eta 0:00:04\n",
      "     --------                                 8.9/42.5 MB 9.3 MB/s eta 0:00:04\n",
      "     --------                                 9.4/42.5 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------                                9.9/42.5 MB 9.4 MB/s eta 0:00:04\n",
      "     ---------                                10.3/42.5 MB 9.4 MB/s eta 0:00:04\n",
      "     ----------                               10.8/42.5 MB 9.5 MB/s eta 0:00:04\n",
      "     ----------                               11.2/42.5 MB 9.5 MB/s eta 0:00:04\n",
      "     -----------                              11.7/42.5 MB 9.6 MB/s eta 0:00:04\n",
      "     -----------                              12.2/42.5 MB 9.8 MB/s eta 0:00:04\n",
      "     -----------                              12.7/42.5 MB 9.9 MB/s eta 0:00:04\n",
      "     ------------                             13.2/42.5 MB 9.9 MB/s eta 0:00:03\n",
      "     ------------                            13.8/42.5 MB 10.1 MB/s eta 0:00:03\n",
      "     -------------                           14.3/42.5 MB 10.2 MB/s eta 0:00:03\n",
      "     -------------                           14.8/42.5 MB 10.4 MB/s eta 0:00:03\n",
      "     --------------                          15.4/42.5 MB 10.4 MB/s eta 0:00:03\n",
      "     --------------                          15.9/42.5 MB 10.4 MB/s eta 0:00:03\n",
      "     ---------------                         16.5/42.5 MB 10.4 MB/s eta 0:00:03\n",
      "     ---------------                         17.0/42.5 MB 10.6 MB/s eta 0:00:03\n",
      "     ----------------                        17.6/42.5 MB 10.7 MB/s eta 0:00:03\n",
      "     ----------------                        18.0/42.5 MB 10.6 MB/s eta 0:00:03\n",
      "     ----------------                        18.3/42.5 MB 10.4 MB/s eta 0:00:03\n",
      "     -----------------                       18.5/42.5 MB 10.2 MB/s eta 0:00:03\n",
      "     -----------------                       18.8/42.5 MB 10.1 MB/s eta 0:00:03\n",
      "     -----------------                        19.1/42.5 MB 9.8 MB/s eta 0:00:03\n",
      "     ------------------                       19.3/42.5 MB 9.6 MB/s eta 0:00:03\n",
      "     ------------------                       19.6/42.5 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------                       19.9/42.5 MB 9.2 MB/s eta 0:00:03\n",
      "     ------------------                       20.1/42.5 MB 9.1 MB/s eta 0:00:03\n",
      "     -------------------                      20.4/42.5 MB 9.0 MB/s eta 0:00:03\n",
      "     -------------------                      20.7/42.5 MB 8.8 MB/s eta 0:00:03\n",
      "     -------------------                      21.0/42.5 MB 8.7 MB/s eta 0:00:03\n",
      "     --------------------                     21.4/42.5 MB 8.6 MB/s eta 0:00:03\n",
      "     --------------------                     21.6/42.5 MB 8.4 MB/s eta 0:00:03\n",
      "     --------------------                     21.9/42.5 MB 8.3 MB/s eta 0:00:03\n",
      "     --------------------                     22.3/42.5 MB 8.2 MB/s eta 0:00:03\n",
      "     ---------------------                    22.6/42.5 MB 8.1 MB/s eta 0:00:03\n",
      "     ---------------------                    22.9/42.5 MB 8.0 MB/s eta 0:00:03\n",
      "     ---------------------                    23.2/42.5 MB 7.9 MB/s eta 0:00:03\n",
      "     ----------------------                   23.6/42.5 MB 7.8 MB/s eta 0:00:03\n",
      "     ----------------------                   24.0/42.5 MB 7.7 MB/s eta 0:00:03\n",
      "     ----------------------                   24.3/42.5 MB 7.6 MB/s eta 0:00:03\n",
      "     -----------------------                  24.6/42.5 MB 7.6 MB/s eta 0:00:03\n",
      "     -----------------------                  24.9/42.5 MB 7.4 MB/s eta 0:00:03\n",
      "     -----------------------                  25.3/42.5 MB 7.4 MB/s eta 0:00:03\n",
      "     ------------------------                 25.7/42.5 MB 7.4 MB/s eta 0:00:03\n",
      "     ------------------------                 26.0/42.5 MB 7.3 MB/s eta 0:00:03\n",
      "     ------------------------                 26.3/42.5 MB 7.2 MB/s eta 0:00:03\n",
      "     -------------------------                26.7/42.5 MB 7.1 MB/s eta 0:00:03\n",
      "     -------------------------                27.1/42.5 MB 7.0 MB/s eta 0:00:03\n",
      "     -------------------------                27.5/42.5 MB 7.0 MB/s eta 0:00:03\n",
      "     --------------------------               27.9/42.5 MB 6.9 MB/s eta 0:00:03\n",
      "     --------------------------               28.3/42.5 MB 7.0 MB/s eta 0:00:03\n",
      "     --------------------------               28.7/42.5 MB 7.0 MB/s eta 0:00:02\n",
      "     ---------------------------              29.0/42.5 MB 7.1 MB/s eta 0:00:02\n",
      "     ---------------------------              29.5/42.5 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------------------------             29.8/42.5 MB 7.4 MB/s eta 0:00:02\n",
      "     ----------------------------             30.3/42.5 MB 7.4 MB/s eta 0:00:02\n",
      "     ----------------------------             30.7/42.5 MB 7.6 MB/s eta 0:00:02\n",
      "     -----------------------------            31.1/42.5 MB 7.7 MB/s eta 0:00:02\n",
      "     -----------------------------            31.5/42.5 MB 7.8 MB/s eta 0:00:02\n",
      "     ------------------------------           31.9/42.5 MB 7.9 MB/s eta 0:00:02\n",
      "     ------------------------------           32.4/42.5 MB 8.0 MB/s eta 0:00:02\n",
      "     ------------------------------           32.8/42.5 MB 8.1 MB/s eta 0:00:02\n",
      "     -------------------------------          33.2/42.5 MB 8.2 MB/s eta 0:00:02\n",
      "     -------------------------------          33.6/42.5 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------------         34.0/42.5 MB 8.3 MB/s eta 0:00:02\n",
      "     --------------------------------         34.5/42.5 MB 8.4 MB/s eta 0:00:01\n",
      "     --------------------------------         34.7/42.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        35.1/42.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        35.5/42.5 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------------------        35.9/42.5 MB 8.4 MB/s eta 0:00:01\n",
      "     ----------------------------------       36.3/42.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------------------------       36.7/42.5 MB 8.5 MB/s eta 0:00:01\n",
      "     ----------------------------------       37.2/42.5 MB 8.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      37.6/42.5 MB 8.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      38.1/42.5 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------------------     38.4/42.5 MB 8.7 MB/s eta 0:00:01\n",
      "     ------------------------------------     38.8/42.5 MB 8.8 MB/s eta 0:00:01\n",
      "     ------------------------------------     39.3/42.5 MB 8.8 MB/s eta 0:00:01\n",
      "     -------------------------------------    39.7/42.5 MB 9.0 MB/s eta 0:00:01\n",
      "     -------------------------------------    40.2/42.5 MB 8.8 MB/s eta 0:00:01\n",
      "     --------------------------------------   40.7/42.5 MB 9.0 MB/s eta 0:00:01\n",
      "     --------------------------------------   41.2/42.5 MB 9.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  41.7/42.5 MB 9.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.2/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  42.5/42.5 MB 9.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 42.5/42.5 MB 7.0 MB/s eta 0:00:00\n",
      "Collecting statsmodels>=0.13.2 (from statsforecast==1.5.0)\n",
      "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
      "                                              0.0/9.1 MB ? eta -:--:--\n",
      "     --                                       0.5/9.1 MB 15.2 MB/s eta 0:00:01\n",
      "     ---                                      0.9/9.1 MB 10.9 MB/s eta 0:00:01\n",
      "     -----                                    1.3/9.1 MB 11.8 MB/s eta 0:00:01\n",
      "     -------                                  1.8/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ----------                               2.3/9.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ------------                             2.7/9.1 MB 10.9 MB/s eta 0:00:01\n",
      "     --------------                           3.3/9.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ----------------                         3.8/9.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------                       4.2/9.1 MB 10.4 MB/s eta 0:00:01\n",
      "     --------------------                     4.7/9.1 MB 10.3 MB/s eta 0:00:01\n",
      "     ----------------------                   5.1/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------                 5.7/9.1 MB 10.7 MB/s eta 0:00:01\n",
      "     --------------------------               6.1/9.1 MB 10.6 MB/s eta 0:00:01\n",
      "     ----------------------------             6.6/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ------------------------------           7.1/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        7.5/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     -----------------------------------      8.1/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     -------------------------------------    8.6/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.1/9.1 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  9.1/9.1 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.1/9.1 MB 10.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsforecast==1.5.0) (4.65.0)\n",
      "Collecting plotly-resampler (from statsforecast==1.5.0)\n",
      "  Downloading plotly_resampler-0.8.3.2.tar.gz (46 kB)\n",
      "                                              0.0/46.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.4/46.4 kB ? eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting fugue>=0.8.1 (from statsforecast==1.5.0)\n",
      "  Downloading fugue-0.8.3-py3-none-any.whl (372 kB)\n",
      "                                              0.0/372.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 372.4/372.4 kB 11.7 MB/s eta 0:00:00\n",
      "Collecting triad>=0.8.4 (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading triad-0.8.6-py3-none-any.whl (77 kB)\n",
      "                                              0.0/77.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.2/77.2 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting adagio>=0.2.4 (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading adagio-0.2.4-py3-none-any.whl (26 kB)\n",
      "Collecting qpd>=0.4.0 (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading qpd-0.4.1-py3-none-any.whl (187 kB)\n",
      "                                              0.0/187.9 kB ? eta -:--:--\n",
      "     ------------------------------------- 187.9/187.9 kB 11.1 MB/s eta 0:00:00\n",
      "Collecting fugue-sql-antlr>=0.1.6 (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading fugue-sql-antlr-0.1.6.tar.gz (154 kB)\n",
      "                                              0.0/154.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 154.6/154.6 kB 9.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pyarrow>=0.15.1 (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading pyarrow-11.0.0-cp310-cp310-win_amd64.whl (20.6 MB)\n",
      "                                              0.0/20.6 MB ? eta -:--:--\n",
      "                                              0.4/20.6 MB 11.9 MB/s eta 0:00:02\n",
      "     -                                        0.6/20.6 MB 10.2 MB/s eta 0:00:02\n",
      "     -                                        0.9/20.6 MB 7.3 MB/s eta 0:00:03\n",
      "     --                                       1.2/20.6 MB 7.5 MB/s eta 0:00:03\n",
      "     --                                       1.5/20.6 MB 6.7 MB/s eta 0:00:03\n",
      "     ---                                      1.7/20.6 MB 6.5 MB/s eta 0:00:03\n",
      "     ---                                      2.0/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     ----                                     2.3/20.6 MB 6.2 MB/s eta 0:00:03\n",
      "     -----                                    2.6/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     -----                                    2.9/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     ------                                   3.1/20.6 MB 6.2 MB/s eta 0:00:03\n",
      "     ------                                   3.4/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     -------                                  3.7/20.6 MB 6.3 MB/s eta 0:00:03\n",
      "     -------                                  4.1/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     --------                                 4.4/20.6 MB 6.3 MB/s eta 0:00:03\n",
      "     ---------                                4.7/20.6 MB 6.5 MB/s eta 0:00:03\n",
      "     ---------                                5.0/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     ----------                               5.3/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     ----------                               5.6/20.6 MB 6.4 MB/s eta 0:00:03\n",
      "     -----------                              6.0/20.6 MB 6.5 MB/s eta 0:00:03\n",
      "     ------------                             6.3/20.6 MB 6.6 MB/s eta 0:00:03\n",
      "     ------------                             6.6/20.6 MB 6.5 MB/s eta 0:00:03\n",
      "     -------------                            7.0/20.6 MB 6.6 MB/s eta 0:00:03\n",
      "     --------------                           7.3/20.6 MB 6.7 MB/s eta 0:00:02\n",
      "     --------------                           7.7/20.6 MB 6.7 MB/s eta 0:00:02\n",
      "     ---------------                          8.0/20.6 MB 6.6 MB/s eta 0:00:02\n",
      "     ----------------                         8.3/20.6 MB 6.7 MB/s eta 0:00:02\n",
      "     -----------------                        8.7/20.6 MB 6.7 MB/s eta 0:00:02\n",
      "     -----------------                        9.1/20.6 MB 6.8 MB/s eta 0:00:02\n",
      "     ------------------                       9.4/20.6 MB 6.8 MB/s eta 0:00:02\n",
      "     -------------------                      9.8/20.6 MB 6.8 MB/s eta 0:00:02\n",
      "     -------------------                      10.2/20.6 MB 6.9 MB/s eta 0:00:02\n",
      "     --------------------                     10.5/20.6 MB 6.8 MB/s eta 0:00:02\n",
      "     ---------------------                    11.0/20.6 MB 6.8 MB/s eta 0:00:02\n",
      "     ----------------------                   11.4/20.6 MB 6.9 MB/s eta 0:00:02\n",
      "     ----------------------                   11.7/20.6 MB 7.0 MB/s eta 0:00:02\n",
      "     -----------------------                  12.1/20.6 MB 7.2 MB/s eta 0:00:02\n",
      "     ------------------------                 12.5/20.6 MB 7.3 MB/s eta 0:00:02\n",
      "     -------------------------                12.9/20.6 MB 7.4 MB/s eta 0:00:02\n",
      "     -------------------------                13.3/20.6 MB 7.4 MB/s eta 0:00:01\n",
      "     --------------------------               13.7/20.6 MB 7.5 MB/s eta 0:00:01\n",
      "     ---------------------------              14.3/20.6 MB 7.7 MB/s eta 0:00:01\n",
      "     ----------------------------             14.6/20.6 MB 7.7 MB/s eta 0:00:01\n",
      "     -----------------------------            15.0/20.6 MB 7.8 MB/s eta 0:00:01\n",
      "     -----------------------------            15.2/20.6 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------           15.6/20.6 MB 7.8 MB/s eta 0:00:01\n",
      "     -------------------------------          16.0/20.6 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------------------          16.3/20.6 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------------------         16.7/20.6 MB 8.0 MB/s eta 0:00:01\n",
      "     ---------------------------------        17.1/20.6 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------------        17.5/20.6 MB 8.1 MB/s eta 0:00:01\n",
      "     ----------------------------------       17.9/20.6 MB 8.1 MB/s eta 0:00:01\n",
      "     -----------------------------------      18.3/20.6 MB 8.2 MB/s eta 0:00:01\n",
      "     ------------------------------------     18.7/20.6 MB 8.3 MB/s eta 0:00:01\n",
      "     -------------------------------------    19.2/20.6 MB 8.4 MB/s eta 0:00:01\n",
      "     --------------------------------------   19.8/20.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.3/20.6 MB 8.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.5/20.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  20.5/20.6 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 20.6/20.6 MB 8.1 MB/s eta 0:00:00\n",
      "Collecting pandas>=1.3.5 (from statsforecast==1.5.0)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "                                              0.0/10.4 MB ? eta -:--:--\n",
      "     -                                        0.5/10.4 MB 14.5 MB/s eta 0:00:01\n",
      "     ---                                      1.0/10.4 MB 12.1 MB/s eta 0:00:01\n",
      "     -----                                    1.4/10.4 MB 11.2 MB/s eta 0:00:01\n",
      "     -------                                  1.9/10.4 MB 10.8 MB/s eta 0:00:01\n",
      "     ---------                                2.4/10.4 MB 10.9 MB/s eta 0:00:01\n",
      "     -----------                              2.9/10.4 MB 10.3 MB/s eta 0:00:01\n",
      "     -------------                            3.4/10.4 MB 10.4 MB/s eta 0:00:01\n",
      "     ---------------                          4.0/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     -----------------                        4.5/10.4 MB 10.7 MB/s eta 0:00:01\n",
      "     -------------------                      5.0/10.4 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------                    5.5/10.4 MB 10.4 MB/s eta 0:00:01\n",
      "     -----------------------                  6.1/10.4 MB 10.5 MB/s eta 0:00:01\n",
      "     -------------------------                6.6/10.4 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------              7.1/10.4 MB 10.8 MB/s eta 0:00:01\n",
      "     ----------------------------             7.5/10.4 MB 10.4 MB/s eta 0:00:01\n",
      "     -------------------------------          8.1/10.4 MB 10.5 MB/s eta 0:00:01\n",
      "     ---------------------------------        8.6/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.1/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------    9.6/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.4/10.4 MB 10.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.4/10.4 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting sqlglot (from fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading sqlglot-11.5.5-py3-none-any.whl (246 kB)\n",
      "                                              0.0/246.7 kB ? eta -:--:--\n",
      "     ------------------------------------- 246.7/246.7 kB 15.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fugue>=0.8.1->statsforecast==1.5.0) (3.1.2)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba>=0.55.0->statsforecast==1.5.0)\n",
      "  Downloading llvmlite-0.39.1-cp310-cp310-win_amd64.whl (23.2 MB)\n",
      "                                              0.0/23.2 MB ? eta -:--:--\n",
      "     -                                        0.6/23.2 MB 13.1 MB/s eta 0:00:02\n",
      "     -                                        1.1/23.2 MB 14.3 MB/s eta 0:00:02\n",
      "     ---                                      1.9/23.2 MB 9.9 MB/s eta 0:00:03\n",
      "     ----                                     2.4/23.2 MB 11.0 MB/s eta 0:00:02\n",
      "     -----                                    3.1/23.2 MB 11.5 MB/s eta 0:00:02\n",
      "     ------                                   3.5/23.2 MB 10.7 MB/s eta 0:00:02\n",
      "     ------                                   4.0/23.2 MB 11.1 MB/s eta 0:00:02\n",
      "     -------                                  4.6/23.2 MB 11.3 MB/s eta 0:00:02\n",
      "     --------                                 5.2/23.2 MB 11.1 MB/s eta 0:00:02\n",
      "     ---------                                5.8/23.2 MB 11.5 MB/s eta 0:00:02\n",
      "     ----------                               6.3/23.2 MB 11.2 MB/s eta 0:00:02\n",
      "     -----------                              6.8/23.2 MB 11.2 MB/s eta 0:00:02\n",
      "     ------------                             7.0/23.2 MB 10.7 MB/s eta 0:00:02\n",
      "     ------------                             7.5/23.2 MB 10.6 MB/s eta 0:00:02\n",
      "     -------------                            7.8/23.2 MB 10.6 MB/s eta 0:00:02\n",
      "     --------------                           8.2/23.2 MB 10.5 MB/s eta 0:00:02\n",
      "     ---------------                          8.8/23.2 MB 10.5 MB/s eta 0:00:02\n",
      "     ----------------                         9.4/23.2 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------                        10.0/23.2 MB 10.7 MB/s eta 0:00:02\n",
      "     -----------------                       10.5/23.2 MB 10.6 MB/s eta 0:00:02\n",
      "     ------------------                      11.1/23.2 MB 10.6 MB/s eta 0:00:02\n",
      "     -------------------                     11.7/23.2 MB 10.7 MB/s eta 0:00:02\n",
      "     --------------------                    12.3/23.2 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------                   12.9/23.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------                  13.4/23.2 MB 11.3 MB/s eta 0:00:01\n",
      "     -----------------------                 14.0/23.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------                14.7/23.2 MB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------               15.3/23.2 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------              15.9/23.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------------             16.7/23.2 MB 11.3 MB/s eta 0:00:01\n",
      "     ----------------------------            17.3/23.2 MB 12.1 MB/s eta 0:00:01\n",
      "     -----------------------------           17.7/23.2 MB 12.4 MB/s eta 0:00:01\n",
      "     ------------------------------          18.3/23.2 MB 12.6 MB/s eta 0:00:01\n",
      "     -------------------------------         18.9/23.2 MB 12.6 MB/s eta 0:00:01\n",
      "     ---------------------------------       19.7/23.2 MB 12.8 MB/s eta 0:00:01\n",
      "     ----------------------------------      20.3/23.2 MB 12.8 MB/s eta 0:00:01\n",
      "     -----------------------------------     21.0/23.2 MB 13.1 MB/s eta 0:00:01\n",
      "     ------------------------------------    21.7/23.2 MB 13.1 MB/s eta 0:00:01\n",
      "     -------------------------------------   22.3/23.2 MB 13.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  22.8/23.2 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.2/23.2 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.2/23.2 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.2/23.2 MB 13.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  23.2/23.2 MB 13.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.2/23.2 MB 9.6 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.21.6 (from statsforecast==1.5.0)\n",
      "  Downloading numpy-1.23.5-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "                                              0.0/14.6 MB ? eta -:--:--\n",
      "     -                                        0.7/14.6 MB 10.4 MB/s eta 0:00:02\n",
      "     ---                                      1.3/14.6 MB 11.6 MB/s eta 0:00:02\n",
      "     -----                                    2.0/14.6 MB 14.0 MB/s eta 0:00:01\n",
      "     -------                                  2.7/14.6 MB 13.2 MB/s eta 0:00:01\n",
      "     ---------                                3.4/14.6 MB 13.7 MB/s eta 0:00:01\n",
      "     -----------                              4.1/14.6 MB 13.6 MB/s eta 0:00:01\n",
      "     -------------                            4.8/14.6 MB 13.9 MB/s eta 0:00:01\n",
      "     ---------------                          5.7/14.6 MB 14.6 MB/s eta 0:00:01\n",
      "     -----------------                        6.4/14.6 MB 14.1 MB/s eta 0:00:01\n",
      "     -------------------                      7.1/14.6 MB 14.1 MB/s eta 0:00:01\n",
      "     ---------------------                    7.8/14.6 MB 14.3 MB/s eta 0:00:01\n",
      "     -----------------------                  8.5/14.6 MB 14.3 MB/s eta 0:00:01\n",
      "     -------------------------                9.2/14.6 MB 14.3 MB/s eta 0:00:01\n",
      "     --------------------------              10.0/14.6 MB 14.5 MB/s eta 0:00:01\n",
      "     ----------------------------            10.7/14.6 MB 14.9 MB/s eta 0:00:01\n",
      "     ------------------------------          11.3/14.6 MB 15.2 MB/s eta 0:00:01\n",
      "     --------------------------------        12.1/14.6 MB 14.9 MB/s eta 0:00:01\n",
      "     ----------------------------------      13.1/14.6 MB 14.9 MB/s eta 0:00:01\n",
      "     ------------------------------------    13.8/14.6 MB 15.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.6/14.6 MB 14.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.6/14.6 MB 14.9 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.6/14.6 MB 13.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from numba>=0.55.0->statsforecast==1.5.0) (65.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.3.5->statsforecast==1.5.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.3.5->statsforecast==1.5.0) (2023.3)\n",
      "Collecting patsy>=0.5.2 (from statsmodels>=0.13.2->statsforecast==1.5.0)\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast==1.5.0) (23.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading contourpy-1.0.7-cp310-cp310-win_amd64.whl (162 kB)\n",
      "                                              0.0/163.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 163.0/163.0 kB ? eta 0:00:00\n",
      "Collecting cycler>=0.10 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "                                              0.0/1.0 MB ? eta -:--:--\n",
      "     --------------------------------         0.8/1.0 MB 26.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 16.1 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "                                              0.0/55.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.3/55.3 kB ? eta 0:00:00\n",
      "Collecting pillow>=6.2.0 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading Pillow-9.5.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "                                              0.0/2.5 MB ? eta -:--:--\n",
      "     ------------                             0.8/2.5 MB 25.4 MB/s eta 0:00:01\n",
      "     -----------------------                  1.5/2.5 MB 15.6 MB/s eta 0:00:01\n",
      "     ----------------------------------       2.2/2.5 MB 15.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 MB 16.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 13.4 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->statsforecast==1.5.0)\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "                                              0.0/98.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 98.3/98.3 kB ? eta 0:00:00\n",
      "Collecting tenacity>=6.2.0 (from plotly->statsforecast==1.5.0)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting dash<3.0.0,>=2.2.0 (from plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading dash-2.9.3-py3-none-any.whl (10.2 MB)\n",
      "                                              0.0/10.2 MB ? eta -:--:--\n",
      "     ---                                      0.8/10.2 MB 17.6 MB/s eta 0:00:01\n",
      "     -----                                    1.5/10.2 MB 18.6 MB/s eta 0:00:01\n",
      "     ---------                                2.4/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "     ------------                             3.1/10.2 MB 16.5 MB/s eta 0:00:01\n",
      "     --------------                           3.8/10.2 MB 17.5 MB/s eta 0:00:01\n",
      "     -----------------                        4.6/10.2 MB 16.3 MB/s eta 0:00:01\n",
      "     ---------------------                    5.4/10.2 MB 16.4 MB/s eta 0:00:01\n",
      "     ------------------------                 6.2/10.2 MB 16.5 MB/s eta 0:00:01\n",
      "     ---------------------------              6.9/10.2 MB 16.4 MB/s eta 0:00:01\n",
      "     -----------------------------            7.6/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------         8.4/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "     -----------------------------------      9.2/10.2 MB 16.3 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.2 MB 16.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.2/10.2 MB 16.8 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.2/10.2 MB 13.6 MB/s eta 0:00:00\n",
      "Collecting jupyter-dash>=0.4.2 (from plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "Collecting orjson<4.0.0,>=3.8.0 (from plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading orjson-3.8.10-cp310-none-win_amd64.whl (197 kB)\n",
      "                                              0.0/197.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 197.1/197.1 kB ? eta 0:00:00\n",
      "Collecting trace-updater>=0.0.8 (from plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading trace_updater-0.0.9.1-py3-none-any.whl (185 kB)\n",
      "                                              0.0/185.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 185.2/185.2 kB 10.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->statsforecast==1.5.0) (0.4.6)\n",
      "Collecting Flask>=1.0.4 (from dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "                                              0.0/101.8 kB ? eta -:--:--\n",
      "     -------------------------------------- 101.8/101.8 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting dash-html-components==2.0.0 (from dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting dash-table==5.0.0 (from dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Collecting antlr4-python3-runtime<4.12,>=4.11.1 (from fugue-sql-antlr>=0.1.6->fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
      "                                              0.0/144.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 144.2/144.2 kB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (2.28.2)\n",
      "Collecting retrying (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (8.12.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (6.22.0)\n",
      "Collecting ansi2html (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (1.5.6)\n",
      "Requirement already satisfied: six in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->statsforecast==1.5.0) (1.16.0)\n",
      "Collecting fs (from triad>=0.8.4->fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "                                              0.0/135.3 kB ? eta -:--:--\n",
      "     -------------------------------------- 135.3/135.3 kB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->fugue>=0.8.1->statsforecast==1.5.0) (2.1.2)\n",
      "Collecting Werkzeug>=2.2.2 (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "                                              0.0/233.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 233.6/233.6 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.0 (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.0 (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler->statsforecast==1.5.0)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "                                              0.0/96.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 96.6/96.6 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting appdirs~=1.4.3 (from fs->triad>=0.8.4->fugue>=0.8.1->statsforecast==1.5.0)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (8.2.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (5.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.1.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (25.0.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (6.3.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (5.9.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (2022.12.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jedi>=0.16->ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.8.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (3.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\david\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from stack-data->ipython->jupyter-dash>=0.4.2->plotly-resampler->statsforecast==1.5.0) (0.2.2)\n",
      "Building wheels for collected packages: plotly-resampler, fugue-sql-antlr\n",
      "  Building wheel for plotly-resampler (pyproject.toml): started\n",
      "  Building wheel for plotly-resampler (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for plotly-resampler: filename=plotly_resampler-0.8.3.2-cp310-cp310-win_amd64.whl size=47910 sha256=a105fda695553f38085fa9555fde2cf931cf06466803da2cb3cd85ca80131db5\n",
      "  Stored in directory: c:\\users\\david\\appdata\\local\\pip\\cache\\wheels\\a9\\19\\e2\\ec856d98cf9b617511fff0abae1dfed5bf1f6093ce65126b45\n",
      "  Building wheel for fugue-sql-antlr (pyproject.toml): started\n",
      "  Building wheel for fugue-sql-antlr (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fugue-sql-antlr: filename=fugue_sql_antlr-0.1.6-py3-none-any.whl size=158069 sha256=3fa4b48b156c85a8b10af9b4739394bd6183a874d6bb927c532eafb7184ba42c\n",
      "  Stored in directory: c:\\users\\david\\appdata\\local\\pip\\cache\\wheels\\c8\\54\\a1\\b294b8b33c6107946b5720b3acb1fce07b97bbbc9677a501ce\n",
      "Successfully built plotly-resampler fugue-sql-antlr\n",
      "Installing collected packages: trace-updater, sqlglot, dash-table, dash-html-components, dash-core-components, appdirs, antlr4-python3-runtime, Werkzeug, tenacity, retrying, pyparsing, pillow, orjson, numpy, llvmlite, kiwisolver, itsdangerous, fs, fonttools, cycler, click, ansi2html, scipy, pyarrow, plotly, patsy, pandas, numba, Flask, contourpy, triad, statsmodels, matplotlib, dash, fugue-sql-antlr, adagio, qpd, jupyter-dash, plotly-resampler, fugue, statsforecast\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n"
     ]
    }
   ],
   "source": [
    "# You'll see a lot of \"WARNING: Retrying\" outputs if you don't have internet enabled\n",
    "# This happens because you haven't verified your phone number for your Kaggle profile.\n",
    "# To do that, you'll need to exit the notebook, go to your profile, go to \"account\", and verify your phone number.\n",
    "# Other than that, don't worry about any error outputs you see from this\n",
    "! pip install statsforecast==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import ARIMA, HoltWinters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data to date/dept_id level\n",
    "\n",
    "train_data = data.groupby(['date', 'dept_id']).sales.agg('sum').reset_index()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data.rename(columns={\n",
    "    'dept_id': 'unique_id',\n",
    "    'date': 'ds',\n",
    "    'sales': 'y'\n",
    "})\n",
    "train_df = df[df.ds < pd.Timestamp('2016-04-24')]\n",
    "\n",
    "sf = StatsForecast(\n",
    "    models=[\n",
    "        # SARIMA(1, 1, 1)(1, 1, 1),7\n",
    "        ARIMA(order=(1, 1, 1), seasonal_order=(1, 1, 1), season_length=7),\n",
    "        # ETS model\n",
    "        HoltWinters(season_length=7)\n",
    "    ],\n",
    "    freq='D'\n",
    ")\n",
    "sf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_df = sf.predict(h=28)\n",
    "forecast_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are `plotly` charts, which are interactive. If you're not familiar, you can:\n",
    "- Click a series name in the legend (on the right) to activate/deactivate it in the plots\n",
    "- Hover your mouse over the plots and click + drag to zoom in\n",
    "- Double click on the plots to zoom back out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.plot(df, forecast_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5768b04258121350f986a32a10c2b5b63ea833426012d4b5b8a887aeeef377c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
